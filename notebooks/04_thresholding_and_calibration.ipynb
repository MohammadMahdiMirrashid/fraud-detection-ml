{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 â€” Threshold Optimization & Calibration\n",
        "\n",
        "Fraud detection requires tuning thresholds based on:\n",
        "- Precision-Recall tradeoffs\n",
        "- Business cost matrix\n",
        "- Investigator workload constraints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "from src.models.thresholding import (\n",
        "    find_optimal_threshold, plot_precision_recall_curve,\n",
        "    plot_roc_curve, plot_cost_vs_threshold\n",
        ")\n",
        "from src.evaluation.calibration import (\n",
        "    calibrate_probabilities, plot_calibration_curve,\n",
        "    calculate_brier_score, calculate_ece\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load test data and predictions (from previous notebook)\n",
        "# In practice, load from saved model outputs\n",
        "df_test = pd.read_csv(\"../data/processed/features.csv\")\n",
        "# ... load predictions from trained model\n",
        "# For demo, we'll generate example predictions\n",
        "y_test = df_test['fraud'].sample(10000, random_state=42)\n",
        "y_proba = np.random.beta(2, 5, size=len(y_test))  # Example probabilities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ROC / PR Curve Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot PR curve\n",
        "plot_precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Plot ROC curve\n",
        "plot_roc_curve(y_test, y_proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cost-Based Thresholding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find optimal threshold based on cost\n",
        "optimal_threshold, metrics = find_optimal_threshold(\n",
        "    y_test, y_proba,\n",
        "    fraud_loss_cost=1000.0,  # Cost of missing fraud\n",
        "    false_positive_cost=10.0,  # Cost of false alarm\n",
        "    max_investigations=None  # No constraint\n",
        ")\n",
        "\n",
        "print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
        "print(f\"Total cost: ${metrics['total_cost']:,.2f}\")\n",
        "print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "\n",
        "# Plot cost vs threshold\n",
        "plot_cost_vs_threshold(y_test, y_proba, fraud_loss_cost=1000.0, false_positive_cost=10.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Calibration: Platt Scaling / Isotonic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibrate probabilities\n",
        "y_proba_calibrated = calibrate_probabilities(y_proba, y_test, method='isotonic')\n",
        "\n",
        "# Calculate calibration metrics\n",
        "brier_uncal = calculate_brier_score(y_test, y_proba)\n",
        "brier_cal = calculate_brier_score(y_test, y_proba_calibrated)\n",
        "ece_uncal = calculate_ece(y_test, y_proba)\n",
        "ece_cal = calculate_ece(y_test, y_proba_calibrated)\n",
        "\n",
        "print(f\"Brier Score - Uncalibrated: {brier_uncal:.4f}, Calibrated: {brier_cal:.4f}\")\n",
        "print(f\"ECE - Uncalibrated: {ece_uncal:.4f}, Calibrated: {ece_cal:.4f}\")\n",
        "\n",
        "# Plot calibration curve\n",
        "plot_calibration_curve(y_test, y_proba, y_proba_calibrated)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
